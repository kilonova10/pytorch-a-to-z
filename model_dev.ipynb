{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write a standard FCN net model for segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc as misc\n",
    "import torch\n",
    "import copy\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def _init_(self, num_classes = 2):\n",
    "        ## Standard FCN model\n",
    "            super(Net, self).__init__()\n",
    "            ## resnet 50 acts as an encoder\n",
    "            self.Encoder = models.resnet50(pretrained=True)\n",
    "            # \n",
    "            self.PSPScales = [1, 1 / 2, 1 / 4, 1 / 8]\n",
    "            \n",
    "            self.PSPLayers = nn.ModuleList() ## decoder layers\n",
    "            \n",
    "            for scale in self.PSPScales:\n",
    "                self.PSPLayers.append(nn.Sequential(nn.Conv2d(2048, 1024, stride = 1, kernel_size = 3, padding = 1, bias = True)))\n",
    "            \n",
    "            self.PSPSqueeze = nn.Sequential(\n",
    "                nn.Conv2d(4096, 512, stride = 1, kernel_size = 1, padding = 0, bias = False),\n",
    "                nn.BatcNorm2d(512),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(512, 512, stride = 1, kernel_size = 3, padding = 0, bias = False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            \n",
    "            ## skip connection layers\n",
    "            \n",
    "            self.SkipConnections = nn.ModuleList()\n",
    "            self.SkipConnections.append(nn.Sequential(\n",
    "                nn.Conv2d(1024, 512, stride = 1, kernel_size = 1, padding = 0, bias = False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.ReLU()))\n",
    "            self.SkipConnections.append(nn.Sequential(\n",
    "                nn.Conv2d(512, 256, stride = 1, kernel_size = 1, padding = 0, bias = False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU()))\n",
    "            self.SkipConnections.append(nn.Sequential(\n",
    "                nn.Conv2d(256, 128, stride=1, kernel_size=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU()))\n",
    "            \n",
    "            ## skip squeeze applied\n",
    "            \n",
    "            self.SqueezeUpsample = nn.ModuleList()\n",
    "            self.SqueezeUpsample.append(nn.Sequential(\n",
    "                nn.Conv2d(1024, 512, stride=1, kernel_size=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.ReLU()))\n",
    "            self.SqueezeUpsample.append(nn.Sequential(\n",
    "                nn.Conv2d(256 + 512, 256, stride=1, kernel_size=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU()))\n",
    "            self.SqueezeUpsample.append(nn.Sequential(\n",
    "                nn.Conv2d(256 + 128, 128, stride=1, kernel_size=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU()))\n",
    "            \n",
    "            ## final prediction for region/pixel\n",
    "            \n",
    "            self.FinalPrediction= nn.Conv2d(128, NumClasses, stride = 1, kernel_size = 3, padding = 1, bias = False)\n",
    "            \n",
    "            ## an attention layer combining the pointer pixel and ROI mask\n",
    "    def AddAttentionLayer(self):\n",
    "        self.AttentionLayers = nn.ModuleList()\n",
    "        self.ROIEncoder = nn.Conv2d(1, 64, stride = 1, kernel_size =3, padding = 1, bias = True)\n",
    "        self.ROIEncoder.bias.data = torch.zeros(self.ROIEncoder.bias.data.shape)\n",
    "        self.ROIEncoder.weight.data = torch.zeros(self.ROIEncoder.weight.data.shape)\n",
    "        \n",
    "        self.PointerEncoder = nn.Conv2d(1, 64, stride = 1, kernel_size = 3, padding = 1, bias = True)\n",
    "        self.PointerEncoder.bias.data = torch.zeros(self.PointerEncoder.bias.data.shape)\n",
    "        self.PointerEncoder.weight.data = torch.zeros(self.PointerEncoder.weight.data.shape)\n",
    "    \n",
    "    def forward(self,Images,Pointer,ROI,UseGPU=True):\n",
    "\n",
    "        #Convert image to pytorch \n",
    "        RGBMean = [123.68,116.779,103.939]\n",
    "        RGBStd = [65,65,65]\n",
    "        InpImages = torch.autograd.Variable(torch.from_numpy(Images.astype(float)), requires_grad=False).transpose(2,3).transpose(1, 2).type(torch.FloatTensor)\n",
    "\n",
    "        #Convert ROI mask and pointer point mask into pytorch\n",
    "        ROImap = torch.autograd.Variable(torch.from_numpy(ROI.astype(np.float)), requires_grad=False).unsqueeze(dim=1).type(torch.FloatTensor)\n",
    "        Pointermap = torch.autograd.Variable(torch.from_numpy(Pointer.astype(np.float)), requires_grad=False).unsqueeze(dim=1).type(torch.FloatTensor)\n",
    "\n",
    "        #Normalize image values\n",
    "        for i in range(len(RGBMean)): InpImages[:, i, :, :]=(InpImages[:, i, :, :]-RGBMean[i])/RGBStd[i] # normalize image values\n",
    "        x=InpImages\n",
    "        SkipConFeatures=[] \n",
    "\n",
    "        #Run Encoder first layer\n",
    "        x = self.Encoder.conv1(x)\n",
    "        x = self.Encoder.bn1(x)\n",
    "\n",
    "        #Convert ROI mask and pointer map into attention layer and merge with image feature mask\n",
    "        r = self.ROIEncoder(ROImap) # Generate attention map from ROI mask\n",
    "        pt = self.PointerEncoder(Pointermap) # Generate attention Mask from Pointer point\n",
    "        sp = (x.shape[2], x.shape[3])\n",
    "        pt = nn.functional.interpolate(pt, size=sp, mode='bilinear')  #\n",
    "        r = nn.functional.interpolate(r, size=sp, mode='bilinear')  # Resize\n",
    "        x = x* pt + r # Merge feature mask and attention maps\n",
    "\n",
    "        #Run remaining encoder layer\n",
    "        x = self.Encoder.relu(x)\n",
    "        x = self.Encoder.maxpool(x)\n",
    "        x = self.Encoder.layer1(x)\n",
    "        SkipConFeatures.append(x)\n",
    "        x = self.Encoder.layer2(x)\n",
    "        SkipConFeatures.append(x)\n",
    "        x = self.Encoder.layer3(x)\n",
    "        SkipConFeatures.append(x)\n",
    "\n",
    "        x = self.Encoder.layer4(x)\n",
    "        PSPSize=(x.shape[2],x.shape[3]) # Size of the original features map\n",
    "\n",
    "        PSPFeatures=[] # Results of various of scaled procceessing\n",
    "        for i,PSPLayer in enumerate(self.PSPLayers): # run PSP layers scale features map to various of sizes apply convolution and concat the results\n",
    "            NewSize=(np.array(PSPSize)*self.PSPScales[i]).astype(np.int)\n",
    "            if NewSize[0] < 1: NewSize[0] = 1\n",
    "            if NewSize[1] < 1: NewSize[1] = 1\n",
    "\n",
    "            # print(str(i)+\")\"+str(NewSize))\n",
    "            y = nn.functional.interpolate(x, tuple(NewSize), mode='bilinear')\n",
    "            #print(y.shape)\n",
    "            y = PSPLayer(y)\n",
    "            y = nn.functional.interpolate(y, PSPSize, mode='bilinear')\n",
    "\n",
    "            PSPFeatures.append(y)\n",
    "        x=torch.cat(PSPFeatures,dim=1)\n",
    "        x=self.PSPSqueeze(x)\n",
    "        for i in range(len(self.SkipConnections)):\n",
    "            sp=(SkipConFeatures[-1-i].shape[2],SkipConFeatures[-1-i].shape[3])\n",
    "            x=nn.functional.interpolate(x,size=sp,mode='bilinear') #Resize\n",
    "            x = torch.cat((self.SkipConnections[i](SkipConFeatures[-1-i]),x), dim=1)\n",
    "            x = self.SqueezeUpsample[i](x)\n",
    "        # Final prediction\n",
    "        x = self.FinalPrdiction(x) # Make prediction per pixel\n",
    "        x = nn.functional.interpolate(x,size=InpImages.shape[2:4],mode='bilinear') # Resize to original image size\n",
    "#********************************************************************************************************\n",
    "        Prob=F.softmax(x,dim=1) # Calculate class probability per pixel\n",
    "        tt,Labels=x.max(1) \n",
    "        return Prob,Labels\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
